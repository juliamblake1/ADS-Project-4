{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703f5f87",
   "metadata": {},
   "source": [
    "# Machine Learning Fairness Algorithms Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d16f8a",
   "metadata": {},
   "source": [
    "#### Fairness in Machine Learning\n",
    "The aim of a fairness algorithm is to avoid the outcome decisions are being made unfairly to certain groups or individuals.\n",
    "- Algorithms are made by humans and trained by data which may be biased\n",
    "- However, there are many definitions of fairness that cannot be optimized at the same time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507a911",
   "metadata": {},
   "source": [
    "#### Learning fair representations (LFR)\n",
    "The main idea: map each individual, represented as a data point in a given input space, to a probability distribution in a new representation space. The aim of this new representation is to lose any information that can identify whether the person belongs to the protected subgroup, while retaining as much other information as possible.\n",
    "\n",
    "A discriminative clustering model, where the prototypes act as the clusters\n",
    "\n",
    "#### Prejudice Remover Regularizer (PR)\n",
    "\n",
    "ADD DETAILS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c33f6",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b925f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import scipy.optimize as optim\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beb8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/juliamblake1/ADS-Project-4/main/data/compas-scores-two-years.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc23109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez            2013-08-14  Male   \n",
       "1   3         kevon dixon   kevon        dixon            2013-01-27  Male   \n",
       "2   4            ed philo      ed        philo            2013-04-14  Male   \n",
       "3   5         marcu brown   marcu        brown            2013-01-13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis            2013-03-26  Male   \n",
       "\n",
       "          dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  1947-04-18   69  Greater than 45             Other  ...               1   \n",
       "1  1982-01-22   34          25 - 45  African-American  ...               1   \n",
       "2  1991-05-14   24     Less than 25  African-American  ...               3   \n",
       "3  1993-01-21   23     Less than 25  African-American  ...               6   \n",
       "4  1973-01-22   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low        2013-08-14  2014-07-07   2014-07-14               0   \n",
       "1           Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2           Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3        Medium        2013-01-13         NaN          NaN               1   \n",
       "4           Low        2013-03-26         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas_scores = pd.read_csv(data,header =0)\n",
    "compas_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d2ab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>edward riddle</td>\n",
       "      <td>edward</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>1974-07-23</td>\n",
       "      <td>41</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>elizabeth thieme</td>\n",
       "      <td>elizabeth</td>\n",
       "      <td>thieme</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>Female</td>\n",
       "      <td>1976-06-03</td>\n",
       "      <td>39</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>2014-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>10994</td>\n",
       "      <td>jarred payne</td>\n",
       "      <td>jarred</td>\n",
       "      <td>payne</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>Male</td>\n",
       "      <td>1985-07-31</td>\n",
       "      <td>30</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>10995</td>\n",
       "      <td>raheem smith</td>\n",
       "      <td>raheem</td>\n",
       "      <td>smith</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995-06-28</td>\n",
       "      <td>20</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>High</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven</td>\n",
       "      <td>butler</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm</td>\n",
       "      <td>simmons</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id              name      first     last compas_screening_date  \\\n",
       "1         3       kevon dixon      kevon    dixon            2013-01-27   \n",
       "2         4          ed philo         ed    philo            2013-04-14   \n",
       "3         5       marcu brown      marcu    brown            2013-01-13   \n",
       "6         8     edward riddle     edward   riddle            2014-02-19   \n",
       "8        10  elizabeth thieme  elizabeth   thieme            2014-03-16   \n",
       "...     ...               ...        ...      ...                   ...   \n",
       "7207  10994      jarred payne     jarred    payne            2014-05-10   \n",
       "7208  10995      raheem smith     raheem    smith            2013-10-20   \n",
       "7209  10996     steven butler     steven   butler            2013-11-23   \n",
       "7210  10997   malcolm simmons    malcolm  simmons            2014-02-01   \n",
       "7212  11000       farrah jean     farrah     jean            2014-03-09   \n",
       "\n",
       "         sex         dob  age       age_cat              race  ...  \\\n",
       "1       Male  1982-01-22   34       25 - 45  African-American  ...   \n",
       "2       Male  1991-05-14   24  Less than 25  African-American  ...   \n",
       "3       Male  1993-01-21   23  Less than 25  African-American  ...   \n",
       "6       Male  1974-07-23   41       25 - 45         Caucasian  ...   \n",
       "8     Female  1976-06-03   39       25 - 45         Caucasian  ...   \n",
       "...      ...         ...  ...           ...               ...  ...   \n",
       "7207    Male  1985-07-31   30       25 - 45  African-American  ...   \n",
       "7208    Male  1995-06-28   20  Less than 25  African-American  ...   \n",
       "7209    Male  1992-07-17   23  Less than 25  African-American  ...   \n",
       "7210    Male  1993-03-25   23  Less than 25  African-American  ...   \n",
       "7212  Female  1982-11-17   33       25 - 45  African-American  ...   \n",
       "\n",
       "      v_decile_score  v_score_text  v_screening_date  in_custody  out_custody  \\\n",
       "1                  1           Low        2013-01-27  2013-01-26   2013-02-05   \n",
       "2                  3           Low        2013-04-14  2013-06-16   2013-06-16   \n",
       "3                  6        Medium        2013-01-13         NaN          NaN   \n",
       "6                  2           Low        2014-02-19  2014-03-31   2014-04-18   \n",
       "8                  1           Low        2014-03-16  2014-03-15   2014-03-18   \n",
       "...              ...           ...               ...         ...          ...   \n",
       "7207               2           Low        2014-05-10  2015-10-22   2015-10-22   \n",
       "7208               9          High        2013-10-20  2014-04-07   2014-04-27   \n",
       "7209               5        Medium        2013-11-23  2013-11-22   2013-11-24   \n",
       "7210               5        Medium        2014-02-01  2014-01-31   2014-02-02   \n",
       "7212               2           Low        2014-03-09  2014-03-08   2014-03-09   \n",
       "\n",
       "      priors_count.1 start   end event two_year_recid  \n",
       "1                  0     9   159     1              1  \n",
       "2                  4     0    63     0              1  \n",
       "3                  1     0  1174     0              0  \n",
       "6                 14     5    40     1              1  \n",
       "8                  0     2   747     0              0  \n",
       "...              ...   ...   ...   ...            ...  \n",
       "7207               0     0   529     1              1  \n",
       "7208               0     0   169     0              0  \n",
       "7209               0     1   860     0              0  \n",
       "7210               0     1   790     0              0  \n",
       "7212               3     0   754     0              0  \n",
       "\n",
       "[6150 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas_scores_race = compas_scores.loc[compas_scores['race'].isin(['Caucasian' ,'African-American'])]\n",
    "compas_scores_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6753f21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>edward riddle</td>\n",
       "      <td>edward</td>\n",
       "      <td>riddle</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>1974-07-23</td>\n",
       "      <td>41</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-02-19</td>\n",
       "      <td>2014-03-31</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>elizabeth thieme</td>\n",
       "      <td>elizabeth</td>\n",
       "      <td>thieme</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>Female</td>\n",
       "      <td>1976-06-03</td>\n",
       "      <td>39</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-16</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>2014-03-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>1</td>\n",
       "      <td>10994</td>\n",
       "      <td>jarred payne</td>\n",
       "      <td>jarred</td>\n",
       "      <td>payne</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>Male</td>\n",
       "      <td>1985-07-31</td>\n",
       "      <td>30</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>2015-10-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>1</td>\n",
       "      <td>10995</td>\n",
       "      <td>raheem smith</td>\n",
       "      <td>raheem</td>\n",
       "      <td>smith</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>Male</td>\n",
       "      <td>1995-06-28</td>\n",
       "      <td>20</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>High</td>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>1</td>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven</td>\n",
       "      <td>butler</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>1</td>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm</td>\n",
       "      <td>simmons</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>1</td>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      race     id              name      first     last compas_screening_date  \\\n",
       "1        1      3       kevon dixon      kevon    dixon            2013-01-27   \n",
       "2        1      4          ed philo         ed    philo            2013-04-14   \n",
       "3        1      5       marcu brown      marcu    brown            2013-01-13   \n",
       "6        0      8     edward riddle     edward   riddle            2014-02-19   \n",
       "8        0     10  elizabeth thieme  elizabeth   thieme            2014-03-16   \n",
       "...    ...    ...               ...        ...      ...                   ...   \n",
       "7207     1  10994      jarred payne     jarred    payne            2014-05-10   \n",
       "7208     1  10995      raheem smith     raheem    smith            2013-10-20   \n",
       "7209     1  10996     steven butler     steven   butler            2013-11-23   \n",
       "7210     1  10997   malcolm simmons    malcolm  simmons            2014-02-01   \n",
       "7212     1  11000       farrah jean     farrah     jean            2014-03-09   \n",
       "\n",
       "         sex         dob  age       age_cat  ...  v_decile_score  \\\n",
       "1       Male  1982-01-22   34       25 - 45  ...               1   \n",
       "2       Male  1991-05-14   24  Less than 25  ...               3   \n",
       "3       Male  1993-01-21   23  Less than 25  ...               6   \n",
       "6       Male  1974-07-23   41       25 - 45  ...               2   \n",
       "8     Female  1976-06-03   39       25 - 45  ...               1   \n",
       "...      ...         ...  ...           ...  ...             ...   \n",
       "7207    Male  1985-07-31   30       25 - 45  ...               2   \n",
       "7208    Male  1995-06-28   20  Less than 25  ...               9   \n",
       "7209    Male  1992-07-17   23  Less than 25  ...               5   \n",
       "7210    Male  1993-03-25   23  Less than 25  ...               5   \n",
       "7212  Female  1982-11-17   33       25 - 45  ...               2   \n",
       "\n",
       "      v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "1              Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
       "2              Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
       "3           Medium        2013-01-13         NaN          NaN               1   \n",
       "6              Low        2014-02-19  2014-03-31   2014-04-18              14   \n",
       "8              Low        2014-03-16  2014-03-15   2014-03-18               0   \n",
       "...            ...               ...         ...          ...             ...   \n",
       "7207           Low        2014-05-10  2015-10-22   2015-10-22               0   \n",
       "7208          High        2013-10-20  2014-04-07   2014-04-27               0   \n",
       "7209        Medium        2013-11-23  2013-11-22   2013-11-24               0   \n",
       "7210        Medium        2014-02-01  2014-01-31   2014-02-02               0   \n",
       "7212           Low        2014-03-09  2014-03-08   2014-03-09               3   \n",
       "\n",
       "     start   end event two_year_recid  \n",
       "1        9   159     1              1  \n",
       "2        0    63     0              1  \n",
       "3        0  1174     0              0  \n",
       "6        5    40     1              1  \n",
       "8        2   747     0              0  \n",
       "...    ...   ...   ...            ...  \n",
       "7207     0   529     1              1  \n",
       "7208     0   169     0              0  \n",
       "7209     1   860     0              0  \n",
       "7210     1   790     0              0  \n",
       "7212     0   754     0              0  \n",
       "\n",
       "[6150 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to binary data\n",
    "df_one = pd.get_dummies(compas_scores_race[\"race\"])\n",
    "# print(df_one)\n",
    " \n",
    "# display result\n",
    "df_two = pd.concat((df_one, compas_scores_race), axis=1)\n",
    "df_two = df_two.drop([\"race\"], axis=1)\n",
    "df_two = df_two.drop([\"Caucasian\"], axis=1)\n",
    "new_df = df_two.rename(columns={\"African-American\": \"race\"})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc5b73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    3283\n",
       " 1    2867\n",
       " Name: two_year_recid, dtype: int64,\n",
       " 1    3696\n",
       " 0    2454\n",
       " Name: race, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.two_year_recid.value_counts(), new_df.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827f45f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1     1501\n",
       " 2      895\n",
       " 3      854\n",
       " 4      701\n",
       " 5      602\n",
       " 6      530\n",
       " 7      413\n",
       " 8      273\n",
       " 9      266\n",
       " 10     115\n",
       " Name: v_decile_score, dtype: int64,\n",
       " 0     1710\n",
       " 1     1166\n",
       " 2      712\n",
       " 3      504\n",
       " 4      359\n",
       " 5      299\n",
       " 6      214\n",
       " 7      191\n",
       " 8      168\n",
       " 9      136\n",
       " 10     104\n",
       " 11      91\n",
       " 13      73\n",
       " 12      70\n",
       " 14      52\n",
       " 15      49\n",
       " 16      37\n",
       " 17      34\n",
       " 19      28\n",
       " 18      25\n",
       " 21      22\n",
       " 22      20\n",
       " 20      17\n",
       " 23      15\n",
       " 24      10\n",
       " 25       8\n",
       " 27       7\n",
       " 28       7\n",
       " 26       6\n",
       " 29       5\n",
       " 33       3\n",
       " 30       2\n",
       " 38       2\n",
       " 36       1\n",
       " 37       1\n",
       " 35       1\n",
       " 31       1\n",
       " Name: priors_count, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " new_df.v_decile_score.value_counts(), new_df.priors_count.value_counts(),  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eda379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb03edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efafe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f4455d4",
   "metadata": {},
   "source": [
    "## LFR Implementation\n",
    "First the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9a2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(509)\n",
    "\n",
    "\n",
    "def loss_x(x_new, x_initial):\n",
    "    \"\"\"\n",
    "    Constrains the mapping to Z to be good description of X.\n",
    "    Prototpyes should retain as much initial info as possible.\n",
    "\n",
    "    difference is measured by squared sum of difference\n",
    "\n",
    "\n",
    "    ARGS:\n",
    "    x_new - Prototypes\n",
    "    x_initial - raw data\n",
    "    \"\"\"\n",
    "    return np.mean(np.sum(np.square((x_new - x_initial))))\n",
    "\n",
    "\n",
    "def loss_y(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    This loss term requires that the prediction of y is as accurate as possible:\n",
    "\n",
    "    Computes log loss\n",
    "\n",
    "    ARGS:\n",
    "    y_true - (num_examples, )\n",
    "    y_predicted - (num_examples, )\n",
    "    \"\"\"\n",
    "    # logarithm is undefined in 0 which means y cant be 0 or 1 => we clip it\n",
    "    y_true = np.clip(y_true, 1e-6, 0.999)\n",
    "    y_predicted = np.clip(y_predicted, 1e-6, 0.999)\n",
    "\n",
    "    log_loss = np.sum(y_true * np.log(y_predicted) +\n",
    "                      (1. - y_true) * np.log(1. - y_predicted)) / len(y_true)\n",
    "\n",
    "    return -log_loss\n",
    "\n",
    "\n",
    "def loss_z(M_k_sensitive, M_k_non_sensitive):\n",
    "    \"\"\"\n",
    "    Ensures statistical parity\n",
    "\n",
    "    Calculates L1 distance\n",
    "\n",
    "    Args:\n",
    "    M_k_sensitive - (num_prototypes, )\n",
    "    M_k_non_sensitive - (num_prototypes, )\n",
    "    \"\"\"\n",
    "    return np.sum(np.abs(M_k_sensitive - M_k_non_sensitive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e11ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(X, v, alpha):\n",
    "    \"\"\"\n",
    "    Calculates distance between initial data and each of the prototypes \n",
    "    Formula -> euclidean(x, v * alpha) (alpha is weight for each feature)\n",
    "\n",
    "    ARGS:\n",
    "    X - (num_examples, num_features)\n",
    "    v - (num_prototypes, num_features)\n",
    "    alpha - (num_features, 1)\n",
    "\n",
    "    returns:\n",
    "    dists - (num_examples, num_prototypes)\n",
    "    \"\"\"\n",
    "    num_examples = X.shape[0]\n",
    "    num_prototypes = v.shape[0]\n",
    "    dists = np.zeros(shape=(num_examples, num_prototypes))\n",
    "\n",
    "    # X = X.values  # converting to NumPy, this is needed in case you pass dataframe\n",
    "    for i in range(num_examples):\n",
    "        dist = np.square(X[i] - v)  # squarred distance\n",
    "        dist_alpha = np.multiply(dist, alpha)  # multiplying by weights\n",
    "        sum_ = np.sum(dist_alpha, axis=1)\n",
    "        dists[i] = sum_\n",
    "\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "416e2144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_nk(dists):\n",
    "    \"\"\"\n",
    "    define Mn,k as the probability that x maps to v\n",
    "\n",
    "    Given the definitions of the prototypes as points in\n",
    "    the input space, a set of prototypes induces a natural\n",
    "    probabilistic mapping from X to Z via the softmax\n",
    "\n",
    "    Since we already have distances calcutated we just map them to probabilities\n",
    "\n",
    "    NOTE:\n",
    "    minus distance because smaller the distance better the mapping\n",
    "\n",
    "    ARGS:\n",
    "    dists - (num_examples, num_prototypes)\n",
    "\n",
    "    Return :\n",
    "    mappings - (num_examples, num_prototypes)\n",
    "    \"\"\"\n",
    "    return softmax(-dists, axis=1)  # specifying axis is important\n",
    "\n",
    "\n",
    "def M_k(M_nk):\n",
    "    \"\"\"\n",
    "    Calculate mean of the mapping for each prototype\n",
    "\n",
    "    ARGS:\n",
    "    M_nk - (num_examples, num_prototypes)\n",
    "\n",
    "    Returns:\n",
    "    M_k - mean of the mappings (num_prototypes, )\n",
    "    \"\"\"\n",
    "    return np.mean(M_nk, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd0cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_n_hat(M_nk, v):\n",
    "    \"\"\"\n",
    "    Gets new representation of the data, \n",
    "    Performs simple dot product\n",
    "\n",
    "    ARGS:\n",
    "    M_nk - (num_examples, num_prototypes)\n",
    "    v - (num_prototypes, num_features)\n",
    "\n",
    "    Returns:\n",
    "    x_n_hat - (num_examples, num_features)\n",
    "    \"\"\"\n",
    "    return M_nk @ v\n",
    "\n",
    "\n",
    "def y_hat(M_nk, w):\n",
    "    \"\"\"\n",
    "    Function calculates labels in the new representation space\n",
    "    Performs simple dot product\n",
    "\n",
    "    ARGS:\n",
    "    M_nk - (num_examples, num_prototypes)\n",
    "    w - (num_prototypes, )\n",
    "\n",
    "    returns:\n",
    "    y_hat - (num_examples, )\n",
    "    \"\"\"\n",
    "    return M_nk @ w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f8b4a",
   "metadata": {},
   "source": [
    "Now for the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f505961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_objective(params, data_sensitive, data_non_sensitive, y_sensitive,\n",
    "                    y_non_sensitive,  inference=False, NUM_PROTOTYPES=10, A_x=0.01, A_y=0.1, A_z=0.5,\n",
    "                    print_every=100):\n",
    "    \"\"\"\n",
    "    Function gathers all the helper functions to calculate overall loss\n",
    "\n",
    "    This is further passed to l-bfgs optimizer \n",
    "\n",
    "    ARGS:\n",
    "    params - vector of length (2 * num_features + NUM_PROTOTYPES + NUM_PROTOTYPES * num_features)\n",
    "    data_sensitive - instances belonging to senstive group (num_sensitive_examples, num_features)\n",
    "    data_non_sensitive - similar to data_sensitive (num_non_senitive_examplesm num_features)\n",
    "    y_sensitive - labels for sensitive group (num_sensitive_examples, )\n",
    "    y_non_sensitive - similar to y_sensitive\n",
    "    inference - (optional) if True than will return new dataset instead of loss\n",
    "    NUM_PROTOTYPES - (optional), default 10\n",
    "    A_x - (optional) hyperparameters for loss_X, default 0.01\n",
    "    A_y - (optional) hyperparameters for loss_Y, default 1\n",
    "    A_z - (optional) hyperparameters for loss_Z, default 0.5\n",
    "    print_every - (optional) how often to print loss, default 100\n",
    "    returns:\n",
    "    if inference - False :\n",
    "    float - A_x * L_x + A_y * L_y + A_z * L_z \n",
    "    if inference - True:\n",
    "    x_hat_sensitive, x_hat_non_sensitive, y_hat_sensitive, y_hat_non_sensitive\n",
    "    \"\"\"\n",
    "    optim_objective.iters += 1\n",
    "\n",
    "    num_features = data_sensitive.shape[1]\n",
    "    # extract values for each variable from params vector\n",
    "    alpha_non_sensitive = params[:num_features]\n",
    "    alpha_sensitive = params[num_features:2 * num_features]\n",
    "    w = params[2 * num_features:2 * num_features + NUM_PROTOTYPES]\n",
    "    v = params[2 * num_features + NUM_PROTOTYPES:].reshape(NUM_PROTOTYPES, num_features)\n",
    "\n",
    "    dists_sensitive = distances(data_sensitive, v, alpha_sensitive)\n",
    "    dists_non_sensitive = distances(data_non_sensitive, v, alpha_non_sensitive)\n",
    "\n",
    "    # get probabilities of mappings\n",
    "    M_nk_sensitive = M_nk(dists_sensitive)\n",
    "    M_nk_non_sensitive = M_nk(dists_non_sensitive)\n",
    "\n",
    "    # M_k only used for calcilating loss_y(statistical parity)\n",
    "    M_k_sensitive = M_k(M_nk_sensitive)\n",
    "    M_k_non_sensitive = M_k(M_nk_non_sensitive)\n",
    "    L_z = loss_z(M_k_sensitive, M_k_non_sensitive)  # stat parity\n",
    "\n",
    "    # get new representation of data\n",
    "    x_hat_sensitive = x_n_hat(M_nk_sensitive, v)\n",
    "    x_hat_non_sensitive = x_n_hat(M_nk_non_sensitive, v)\n",
    "    # calculates how close new representation is to original data\n",
    "    L_x_sensitive = loss_x(data_sensitive, x_hat_sensitive)\n",
    "    L_x_non_sensitive = loss_x(data_non_sensitive, x_hat_non_sensitive)\n",
    "\n",
    "    # get new values for labels\n",
    "    y_hat_sensitive = y_hat(M_nk_sensitive, w)\n",
    "    y_hat_non_sensitive = y_hat(M_nk_non_sensitive, w)\n",
    "    # ensure how good new predictions are(log_loss)\n",
    "    L_y_sensitive = loss_y(y_sensitive, y_hat_sensitive)\n",
    "    L_y_non_sensitive = loss_y(y_non_sensitive, y_hat_non_sensitive)\n",
    "\n",
    "    L_x = L_x_sensitive + L_x_non_sensitive\n",
    "    L_y = L_y_sensitive + L_y_non_sensitive\n",
    "\n",
    "    loss = A_x * L_x + A_y * L_y + A_z * L_z\n",
    "\n",
    "    if optim_objective.iters % print_every == 0:\n",
    "        print(f'loss on iteration {optim_objective.iters} : {loss}, L_x - {L_x * A_x} L_y - {L_y * A_y} L_z - {L_z * A_z}')\n",
    "    \n",
    "    if not inference:\n",
    "        return loss\n",
    "    if inference:\n",
    "        return x_hat_sensitive, x_hat_non_sensitive, y_hat_sensitive, y_hat_non_sensitive\n",
    "\n",
    "optim_objective.iters = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff9307",
   "metadata": {},
   "source": [
    "Now lets actually implement after we have all of the functions necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884aee49",
   "metadata": {},
   "source": [
    "We are going to use a subset of the data for trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "529ea133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>race</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      two_year_recid  race  priors_count  v_decile_score  age\n",
       "1                  1     1             0               1   34\n",
       "2                  1     1             4               3   24\n",
       "3                  0     1             1               6   23\n",
       "6                  1     0            14               2   41\n",
       "8                  0     0             0               1   39\n",
       "...              ...   ...           ...             ...  ...\n",
       "7207               1     1             0               2   30\n",
       "7208               0     1             0               9   20\n",
       "7209               0     1             0               5   23\n",
       "7210               0     1             0               5   23\n",
       "7212               0     1             3               2   33\n",
       "\n",
       "[6150 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_df = new_df[['two_year_recid', 'race', 'priors_count', 'v_decile_score', 'age']]\n",
    "use_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5031f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "RACE_SENSITIVE = 0\n",
    "\n",
    "# seperation into sensitive and non sensitive\n",
    "data_sensitive = use_df[use_df.race > RACE_SENSITIVE]\n",
    "data_non_sensitive = use_df[use_df.race <= RACE_SENSITIVE]\n",
    "y_sensitive = data_sensitive.two_year_recid\n",
    "y_non_sensitive = data_non_sensitive.two_year_recid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad08708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 6150 examples and 5 features\n",
      "From which 3696 belong to sensitive group and 2454 to non sensitive group \n"
     ]
    }
   ],
   "source": [
    "print (f'Dataset contains {use_df.shape[0]} examples and {use_df.shape[1]} features')\n",
    "print (f'From which {data_sensitive.shape[0]} belong to sensitive group and {data_non_sensitive.shape[0]} to non sensitive group ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40401d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_sensitive['two_year_recid']\n",
    "del data_non_sensitive['two_year_recid']\n",
    "\n",
    "# Standard Scaling\n",
    "data_sensitive = StandardScaler().fit_transform(data_sensitive)\n",
    "data_non_sensitive = StandardScaler().fit_transform(data_non_sensitive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9534218",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROTOTYPES = 10\n",
    "num_features = data_sensitive.shape[1]\n",
    "\n",
    "params = np.random.uniform(size=(num_features * 2 + NUM_PROTOTYPES + NUM_PROTOTYPES * num_features))\n",
    "# here we generate random weight for each of the features both for sensitive data\n",
    "# and for non sensitive, hence num_features*2(in paper this is denoted as alpha)\n",
    "# alphas are used for calculating distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946c71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then NUM_PROTOTYPES is a weight for each prototype, this is multiplied with \n",
    "# M_nk s and used for calculating y_hat\n",
    "\n",
    "# Next is NUM_PROTOTYPES * num_features which is v(in paper), this is also used\n",
    "# for calculating distances\n",
    "\n",
    "\n",
    "bnd = [] # This is needed for l-bfgs algorithm\n",
    "for i, _ in enumerate(params):\n",
    "    if i < num_features * 2 or i >= num_features * 2 + NUM_PROTOTYPES:\n",
    "        bnd.append((None, None))\n",
    "    else:\n",
    "        bnd.append((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e003cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on iteration 100 : 151.85569488772356, L_x - 151.65946108403293 L_y - 0.14425030879802944 L_z - 0.0519834948925982\n",
      "loss on iteration 200 : 39.96647896619465, L_x - 39.691357292317036 L_y - 0.17105209786542533 L_z - 0.10406957601218769\n",
      "loss on iteration 300 : 26.763019529673617, L_x - 26.498199308874383 L_y - 0.1672788151737492 L_z - 0.09754140562548326\n",
      "loss on iteration 400 : 20.43543421761302, L_x - 20.197125576976127 L_y - 0.15410188024860427 L_z - 0.08420676038829\n",
      "loss on iteration 500 : 17.936021821123116, L_x - 17.70707425010495 L_y - 0.1504740843096172 L_z - 0.07847348670854905\n",
      "loss on iteration 600 : 15.418761747154589, L_x - 15.195824332148804 L_y - 0.14748900431566594 L_z - 0.07544841069011887\n",
      "loss on iteration 700 : 100.4255804349174, L_x - 100.02765991623502 L_y - 0.14011248417582284 L_z - 0.25780803450657186\n",
      "loss on iteration 800 : 11.930876728999314, L_x - 11.748865634385734 L_y - 0.1418637307554593 L_z - 0.04014736385812077\n",
      "loss on iteration 900 : 11.088643160071914, L_x - 10.890994874297713 L_y - 0.14222032824177608 L_z - 0.055427957532424035\n",
      "loss on iteration 1000 : 10.307244039226918, L_x - 10.127461540299908 L_y - 0.14282105819951105 L_z - 0.036961440727498726\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12432\\999441139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m x_hat_senitive, x_hat_nons, y_hat_sens, y_hat_nons = optim_objective(new_params,data_sensitive, data_non_sensitive,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                         y_sensitive, y_non_sensitive, inference=False)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "new_params = optim.fmin_l_bfgs_b(optim_objective, x0=params, epsilon=1e-5,\n",
    "                                  args=(data_sensitive, data_non_sensitive,\n",
    "                                        y_sensitive, y_non_sensitive),\n",
    "                                  bounds=bnd, approx_grad=True, maxfun=1000,\n",
    "                                  maxiter=1000)[0]\n",
    "\n",
    "\n",
    "x_hat_senitive, x_hat_nons, y_hat_sens, y_hat_nons = optim_objective(new_params,data_sensitive, data_non_sensitive,\n",
    "                                        y_sensitive, y_non_sensitive, inference=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3107b685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662151d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
